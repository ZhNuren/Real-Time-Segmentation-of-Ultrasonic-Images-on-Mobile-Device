{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from collections.abc import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import load_model\n",
    "from models.get_model import get_model\n",
    "\n",
    "from monai.networks.blocks.segresnet_block import ResBlock, get_conv_layer, get_upsample_layer\n",
    "from monai.networks.layers.factories import Dropout\n",
    "from monai.networks.layers.utils import get_act_layer, get_norm_layer\n",
    "from monai.utils import UpsampleMode\n",
    "from typing import Union, Tuple, List, Dict, Optional\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"2023-11-18_18-44-38\"\n",
    "\n",
    "run_path = f\"runs/{run_name}/\"\n",
    "\n",
    "train_summary = json.load(open(run_path + \"train_summary.json\"))\n",
    "\n",
    "model_name = train_summary[\"config\"][\"MODEL\"]\n",
    "IMAGE_SIZE = train_summary[\"config\"][\"IMAGE_SIZE\"]\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # RBG to grayscale\n",
    "        x = torch.mean(x, dim=-3, keepdim=True)\n",
    "        # add batch dim\n",
    "        # x = x.unsqueeze(0)\n",
    "\n",
    "        x = self.model(x)\n",
    "        x = x[0]\n",
    "        x = torch.nn.functional.interpolate(x, size=(IMAGE_SIZE, IMAGE_SIZE), mode='bilinear', align_corners=False)\n",
    "        # do argmax\n",
    "        x = torch.softmax(x, dim=1)\n",
    "        x = x[:, 1, ...]\n",
    "        x = x.unsqueeze(1)\n",
    "        x = x > 0.9\n",
    "\n",
    "        res : Dict[str, torch.Tensor] = {}\n",
    "        res[\"out\"] = x\n",
    "        # res = x\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "model = get_model(model_name, IMAGE_SIZE)\n",
    "model = load_model(model, run_path + \"best_model.pth\")\n",
    "\n",
    "model_mobile = MobileWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "model_mobile.eval()\n",
    "example = torch.rand(1, 3, 256, 256)\n",
    "\n",
    "out = model_mobile(example)\n",
    "print(out[\"out\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobile.eval()\n",
    "example = torch.rand(1, 3, 256, 256)\n",
    "traced_module = torch.jit.trace(model_mobile, example, strict=False)\n",
    "# traced_script_module = torch.jit.script(model_mobile)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"model.ptl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "from torch.jit.mobile import (\n",
    "    _backport_for_mobile,\n",
    "    _get_model_bytecode_version,\n",
    ")\n",
    "\n",
    "print(_get_model_bytecode_version(\"model.ptl\"))\n",
    "\n",
    "_backport_for_mobile(\"model.ptl\", \"model_7.ptl\", 7)\n",
    "\n",
    "print(_get_model_bytecode_version(\"model_7.ptl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 21, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "img = torch.rand(1, 3, 256, 256)\n",
    "out = model(img)\n",
    "\n",
    "print(out[\"out\"].shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV701_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
